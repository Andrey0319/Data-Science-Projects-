{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_batch_generator (X, y, my_shuffle=True, batch_size=100): \n",
    "    if my_shuffle:\n",
    "        X, y = shuffle(X, y, random_state=0)\n",
    "    X_batch = np.zeros(shape=(batch_size, len(X[0])))\n",
    "    y_batch = np.zeros(shape=batch_size)\n",
    "    \n",
    "    for i in range(0, len(X) - batch_size, batch_size):\n",
    "        X_batch = [X[j] for j in range(i, i+batch_size)]\n",
    "        y_batch = [y[j] for j in range(i, i+batch_size)]\n",
    "        yield (X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, batch_generator, C=1, alpha=0.01, max_epoch=20,\n",
    "                 model_type='lin_reg', batch_size=1, drag=1):\n",
    "        \"\"\"\n",
    "        batch_generator - функция генератор, которой будем создавать батчи\n",
    "        batch_size      - количество элементов в батче\n",
    "        C               - коэф. регуляризации\n",
    "        alpha           - скорость спуска\n",
    "        max_epoch       - максимальное количество эпох\n",
    "        model_type      - тим модели, lin_reg или log_reg\n",
    "        drag            - коэффициент торможения обучения для улучшения сходимости\n",
    "\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.errors_log = {'iter': [], 'loss': []}\n",
    "        self.model_type = model_type\n",
    "        self.batch_size = batch_size\n",
    "        self.drag = drag\n",
    "\n",
    "    def calc_loss(self, X_batch, y_batch, test_val=True):\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу \n",
    "\n",
    "        X_batch  - матрица объекты-признаки по батчу\n",
    "        y_batch  - вектор ответов по батчу\n",
    "        test_val - является ли тестовой выборкой, если является - добавляет \n",
    "                   колонку единиц для учёта w_0\n",
    "        \"\"\"\n",
    "        if (test_val):\n",
    "            X_batch = self.adds_column_of_ones(X_batch)\n",
    "\n",
    "        loss = -1\n",
    "        if (self.model_type == 'lin_reg'):\n",
    "            arg = [(y_batch[i] - np.dot(self.weights, X_batch[i])) ** 2 for i in range(len(X_batch))]\n",
    "            loss = sum(arg) / len(y_batch)\n",
    "\n",
    "        elif (self.model_type == 'log_reg'):\n",
    "            arg = 0\n",
    "            for i in range(len(X_batch)):\n",
    "                s = sigmoid(np.dot(self.weights, X_batch[i]))\n",
    "                arg += -y_batch[i] * np.log(s) - (1 - y_batch[i]) * np.log(1 - s)\n",
    "            loss = arg / len(X_batch)\n",
    "\n",
    "        return loss + sum(self.weights[1:] ** 2) / self.C\n",
    "\n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        \"\"\"\n",
    "        res = np.zeros(shape=len(self.weights))\n",
    "        loss_grad = 0\n",
    "        if (self.model_type == 'lin_reg'):\n",
    "            for i in range(len(X_batch)):\n",
    "                arg = np.dot(self.weights, X_batch[i]) - y_batch[i]\n",
    "                res += 2 * X_batch[i] * arg / len(X_batch[0]) + 2 * sum(self.weights[1:]) / self.C\n",
    "            loss_grad = -res / len(X_batch)\n",
    "\n",
    "        elif (self.model_type == 'log_reg'):\n",
    "            for i in range(len(X_batch)):\n",
    "                res += X_batch[i] * (y_batch[i] - sigmoid(np.dot(self.weights, X_batch[i])))\n",
    "            loss_grad = res / len(X_batch)\n",
    "\n",
    "        return loss_grad\n",
    "\n",
    "    def update_weights(self, new_grad):\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.weights = (self.weights + self.alpha * new_grad) / (1 + 1 / self.C)\n",
    "        pass\n",
    "\n",
    "    def adds_column_of_ones(self, X):\n",
    "        \"\"\"\n",
    "        добавляет колонку единиц для учёта w_0\n",
    "        \"\"\"\n",
    "        a = np.ones(len(X), dtype=int).reshape(len(X), 1)\n",
    "        X = np.column_stack((a, X))\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        \"\"\"\n",
    "        self.cl_names = np.array(list(map(int, np.unique(y))))\n",
    "        fit_complete = 0;\n",
    "        y = [int(y[i]) for i in range(len(y))]\n",
    "        self.weights = np.array([random.uniform(-0.1, 0.1) for i in range(len(X[0]) + 1)])\n",
    "        self.result = np.zeros(shape=10000)\n",
    "        iteration = 0\n",
    "        X = self.adds_column_of_ones(X)\n",
    "\n",
    "        for n in range(0, self.max_epoch):\n",
    "            X, y = shuffle(X, y, random_state=0)\n",
    "            prev_weights = self.weights\n",
    "            new_epoch_generator = self.batch_generator(X, y, self.batch_size)\n",
    "            for batch_num, new_batch in enumerate(new_epoch_generator):\n",
    "                X_batch = new_batch[0]\n",
    "                y_batch = new_batch[1]\n",
    "\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch, test_val=False)\n",
    "                if (iteration < 10000):\n",
    "                    self.result[iteration] = batch_loss\n",
    "                    iteration += 1\n",
    "\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)  #\n",
    "\n",
    "                prev_batch_grad = batch_grad\n",
    "                self.update_weights(batch_grad)\n",
    "                self.errors_log['iter'].append(batch_num)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "            self.alpha /= self.drag\n",
    "            #print(n, ' = ', self.calc_loss(X, y, test_val=False))\n",
    "            if (np.sum(abs(prev_weights - self.weights)) < 0.e-4):\n",
    "                #print('last epoch: ', n)\n",
    "                break;\n",
    "            if (fit_complete):\n",
    "                break;\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        \"\"\"\n",
    "        X = self.adds_column_of_ones(X)\n",
    "        y_hat = [np.dot(X[i], self.weights) for i in range(len(X))]\n",
    "        self.proba = [self.cl_names[np.argmin(abs(self.cl_names - y_hat[i]))] for i in range(len(y_hat))]\n",
    "        return y_hat\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        считает точность фактического предсказания принадлежности объекта классу\n",
    "        \"\"\"\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        for i in range(len(y)):\n",
    "            if (y[i] == self.proba[i] and self.proba[i] == 1):\n",
    "                tp += 1\n",
    "            if (y[i] == self.proba[i] and self.proba[i] == 0):\n",
    "                tn += 1\n",
    "            if (y[i] != self.proba[i] and self.proba[i] == 1):\n",
    "                fp += 1\n",
    "            if (y[i] == self.proba[i] and self.proba[i] == 0):\n",
    "                fn += 1\n",
    "                \n",
    "        if (tp + fp == 0):\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            \n",
    "        if (tp + fn == 0):\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = tp / (tp + fn)\n",
    "            \n",
    "        if (precision + recall == 0):\n",
    "            s = 0\n",
    "        else:\n",
    "            s = 2 * precision * recall / (precision + recall)\n",
    "            \n",
    "        return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, stratify=y)\n",
    "my_clf = MySGDClassifier(batch_generator=my_batch_generator, max_epoch=1, alpha=0.5, C=10000, batch_size=50)\n",
    "%time my_clf.fit(X_train, y_train)\n",
    "%time my_clf.calc_loss(X_test, y_test)\n",
    "my_clf.predict(X_test)\n",
    "my_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "fig = pylab.figure(figsize = (13, 7))\n",
    "ax = fig.add_subplot(111) \n",
    "ax.plot(my_clf.result)\n",
    "pylab.ylim(0, 1)\n",
    "pylab.xlim(0, 2000)\n",
    "pylab.xlabel('iteration', size=18)\n",
    "pylab.ylabel('calc_loss', size=18)\n",
    "ax.set_title('grafic', size=22)\n",
    "\n",
    "pylab.show()\n",
    "#резкое падение ошибки до нуля - конец обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-21ac24a23735>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(X_train))\n",
    "print(scaler.mean_)\n",
    "print(X_train[:10])\n",
    "X_train = scaler.transform(X_train)\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, stratify=y)\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "max_batch_size = 0\n",
    "max_max_epoch = 0\n",
    "max_drag = 0\n",
    "\n",
    "\n",
    "for alpha_test in range(1, 30, 5):\n",
    "    print('reach alpha: ', alpha_test)\n",
    "    for batch_size_test in range(1, 200, 20):\n",
    "        for max_epoch_test in range(1, 31, 5):\n",
    "            for drag_test in range(101, 120, 4):\n",
    "                \n",
    "                my_clf = MySGDClassifier(batch_generator=my_batch_generator, \n",
    "                                         model_type='log_reg', \n",
    "                                         max_epoch=max_epoch_test, \n",
    "                                         alpha=alpha_test / 100, \n",
    "                                         C=200000, \n",
    "                                         batch_size=batch_size_test, \n",
    "                                         drag=drag_test / 100)\n",
    "                my_clf.fit(X_train, y_train)\n",
    "                my_clf.predict(X_test)\n",
    "                s = my_clf.score(X_test, y_test)\n",
    "                if max_score < s:\n",
    "                    max_score = s\n",
    "                    max_alpha = alpha_test\n",
    "                    max_batch_size = batch_size_test\n",
    "                    max_max_epoch = max_epoch_test\n",
    "                    max_drag = drag_test\n",
    "\n",
    "print('score: ', max_score)\n",
    "print('alpha: ', max_alpha)\n",
    "print('batch_size: ', max_batch_size)\n",
    "print('max_epoch: ', max_max_epoch)\n",
    "print('drag: ', max_drag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
